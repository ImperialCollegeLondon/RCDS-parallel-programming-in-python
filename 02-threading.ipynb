{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threading\n",
    "\n",
    "The ```threading``` library (documentation [here](https://docs.python.org/3/library/threading.html)) is a library which (since Python 3.7) is included by default as part of the Python standard library. It allows us to spawn and run multiple threads concurrently. We will see that it has some significant limitations, but has its uses and is also a good vehicle for learning about concurrency.\n",
    "\n",
    "## Threads\n",
    "A thread is a separate flow of execution within your code. Normally, Python executes on a single thread, but the ```threading``` library allows us to create multiple threads. This allows for there to be multiple point in a code where the code is currently being executed. Each thread will have access to the same memory space, so they can share data between them.\n",
    "\n",
    "## Creating a thread\n",
    "\n",
    "We can create a thread using the ```Thread``` class from the ```threading``` library. We can create a thread by passing a function to the constructor of the ```Thread``` class. We do this by writing ```target=[function name]``` in the argument list. We can also pass arguments to the function by writing ```args=``` and then a tuple containing the arguments in the argument list.\n",
    "\n",
    " We can then start the thread by calling the ```start()``` method on the thread object. In the example below, we create two threads and start them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "# Define a simple function to call\n",
    "def greetings(thread_number):\n",
    "    print(f'Hello from thread {thread_number}')\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    # Create a thread to run the greetings function\n",
    "    # Pass the thread number as an argument in a tuple\n",
    "    # As a reminder, we can create a tuple with a single element by adding a comma after the element\n",
    "    t = threading.Thread(target=greetings, args=(i,))\n",
    "    t.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waiting for a Thread\n",
    "\n",
    "Once the thread has finished executing the function, will be terminated. However, in the meantime, the main thread will continue to execute. If we want to wait for a thread to finish, we can call the ```join()``` method on the thread object. This will block the main thread until the thread has finished executing. When doing this it may be useful to create a collection storing a reference to each thread so we can access them later. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Create a list to hold references to the threads\n",
    "threads = []\n",
    "\n",
    "def wait_for_time(thread_number, seconds):\n",
    "    # time.sleep will pause the current thread for the given number of seconds\n",
    "    time.sleep(seconds)\n",
    "    print(f'Thread {thread_number} waited for {seconds} seconds')\n",
    "\n",
    "# Create 5 threads that will wait for a different amount of time\n",
    "for i in range(5):\n",
    "    # Each thread will wait for between 0 and 2 seconds\n",
    "    t = threading.Thread(target=wait_for_time, args=(i, i / 2))\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "\n",
    "# This line will be printed immediately\n",
    "print('All threads have started')\n",
    "\n",
    "# Wait for all threads to finish\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "# This line will only be printed after all threads are done\n",
    "print('All threads are done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Values from a Thread\n",
    "\n",
    "If the function that we pass to the thread has a return value, this value is not stored by default. If we want to access data created in the thread, we have a couple of simple options (and some more complicated ones we won't be covering in this course). We could pass in a mutable object (like a list or dictionary) and have the thread modify that object. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of threads we'll spawn\n",
    "n = 10\n",
    "\n",
    "# Create a list with n entries of None\n",
    "# The results will be stored in this list\n",
    "results = [None] * n\n",
    "\n",
    "# A function that will calculate the sum of numbers between 0 and end (inclusive)\n",
    "def sum_numbers(end, results):\n",
    "    results[i] = sum(range(end + 1))\n",
    "\n",
    "# Create a list to store the threads\n",
    "threads = []\n",
    "\n",
    "# Create n threads\n",
    "for i in range(0, n):\n",
    "    # Create a thread to run the sum_numbers function\n",
    "    # Pass the start and end as arguments in a tuple\n",
    "    t = threading.Thread(target=sum_numbers, args=(i, results))\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "\n",
    "for t in threads:\n",
    "    # Wait for the threads to finish\n",
    "    t.join()\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also create a mutable object in the main thread, where the thread can deposit its results. For example, we can adopt the previous example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "# The number of threads we'll spawn\n",
    "n = 10\n",
    "\n",
    "# Create a list with n entries of None\n",
    "# The results will be stored in this list\n",
    "results = [None] * n\n",
    "\n",
    "# A function that will calculate the sum of numbers between 0 and end (inclusive)\n",
    "def sum_numbers(end):\n",
    "    # There is no local variable results in this function\n",
    "    # So Python will look for a global variable called results\n",
    "    results[end] = sum(range(end + 1))\n",
    "\n",
    "# Create a list to store the threads\n",
    "threads = []\n",
    "\n",
    "# Create n threads\n",
    "for i in range(0, n):\n",
    "    # Create a thread to run the sum_numbers function\n",
    "    # Pass the start and end as arguments in a tuple\n",
    "    t = threading.Thread(target=sum_numbers, args=(i, ))\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "\n",
    "for t in threads:\n",
    "    # Wait for the threads to finish\n",
    "    t.join()\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Sum of Squares\n",
    "\n",
    "In the code cell below, write some code which will calculate and print the sum of the squares of all of the numbers between 1 and 1,000,000:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{1000000} i^2 = 1^2 + 2^2 + \\ldots + 1000000^2\n",
    "$$\n",
    "\n",
    "You should split the work between two threads using the ```threading``` library. Each thread should calculate the sum of the squares of half of the numbers. The main thread should then combine the results from the two threads to get the final answer. Consider how you might structure your code to do this. The final value should be 333,333,833,333,500,000. A sample solution can be found in the file [sample_solutions/02-threading.ipynb](sample_solutions/02-threading.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order of Execution\n",
    "When multiple threads are running, we cannot guarantee which order "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "def print_numbers(n, thread_number):\n",
    "    for i in range(n):\n",
    "        time.sleep(0.01)\n",
    "        print(f'Thread: {thread_number}, Number: {i}')\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    t = threading.Thread(target=print_numbers, args=(5, i))\n",
    "    t.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run the code above, we see a couple of interesting things. Firstly, when we examine the order of the output, we may see that a thread that is started later may overtake a thread that started earlier, despite them each running identical code. Secondly, if we run the codes multiple times, the order in which the print statements executes may change. These two observations are due to the way that CPU time is allocated to threads, which is controlled by the operating system. This means we cannot guarantee the order in which threads will execute. This is a common feature of concurrent programming, and is something we will need to be aware of when writing concurrent code.\n",
    "\n",
    "Another feature that we may see is that some print statements may be on the same line. This is because a single print statement includes printing the output, and then starting a new line. One print statement may have printed its output but not started a new line before another print statement has printed its output. This leads to the outputs of multiple print statements becoming interleaved. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race Conditions\n",
    "\n",
    "In the example above the exercise, we saw that the function ```sum_numbers``` will be running in multiple threads simultaneously. In each of these threads, the global variable ```results``` will be accessed and modified. In that case, each thread was accessing a different entry in ```results``` and so the different threads didn't interfere with each other. However, if multiple threads are accessing the same data, there can be problems where the threads interfere with each other. This is known as a race condition. For example, in the code below, we write a function which increases the value of the global variable ```x``` by the thread number. Naively, we might expect this to mean that the value of ```x``` at the end of the code running will be equal to the sum of the thread numbers. However, this is not the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "\n",
    "# This is the shared variable that will be incremented by all threads\n",
    "x = 0\n",
    "\n",
    "def increment_x_by_thread_number(thread_number):\n",
    "    # This function will increment x by the thread number\n",
    "\n",
    "    # We need to tell Python that we're using the global x\n",
    "    global x\n",
    "\n",
    "    # Create a local variable to hold the value of x and increment it\n",
    "    local_x = x\n",
    "    local_x += thread_number\n",
    "\n",
    "    # Pause for a moment before updating the global x\n",
    "    time.sleep(0.1)\n",
    "    x =local_x\n",
    "\n",
    "# Run each of the threads\n",
    "threads = []\n",
    "\n",
    "for i in range(5):\n",
    "    t = threading.Thread(target=increment_x_by_thread_number, args=(i,))\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "# What will the value of x be?\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, each thread will start at roughly the same time and the value of ```local_x``` will take the value of ```x```. As the value hasn't been updated in any thread, the value of ```local_x``` will be 0 in each thread. Each thread will pause for a moment before changing the global variable ```x```. The order in which these updates to ```x``` happen is not guaranteed as one thread may overtake another. The final value of ```x``` will be the number of the thread which finishes last. \n",
    "\n",
    "Even though the function in each thread increments ```x``` by the number of that thread, the final value of ```x``` will not be the sum of the thread numbers. This is an example of what is known as a \"race condition\", where the code executing an a thread may be working on outdated values, or may overwrite the work of another thread. This can lead to unpredictable behaviour and bugs in your code. \n",
    "\n",
    "In this example, we guaranteed a race condition would occur. But, as the order in which the operations in the thread execute is not guaranteed, it is not uncommon for race conditions to occur sometimes but not others in threaded code. This makes it difficult to debug and test threaded code.\n",
    "\n",
    "For this reason, when working with threads, you should think carefully about which bits of data your a function run in a thread might be accessing or writing and whether this could change during the execution of the thread. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locks\n",
    "\n",
    "One way to prevent threads interfering with shared data while other threads may be using it is to use a lock. A lock is an object which can be acquired by a thread. If a thread tries to acquire a lock that is already acquired by another thread, the thread will pause until the lock is released. This can be used to temporarily pause a thread while shared data is being accessed by another thread. We can create a thread by writing ```threading.Lock()``` and acquire a lock by writing ```lock.acquire()```. We can release a lock by writing ```lock.release()```. For example, the code below adapts the previous example to use a lock:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "\n",
    "# This is the shared variable that will be incremented by all threads\n",
    "x = 0\n",
    "\n",
    "lock = threading.Lock()\n",
    "\n",
    "def increment_x_by_thread_number(thread_number):\n",
    "    # This function will increment x by the thread number\n",
    "\n",
    "    # We need to tell Python that we're using the global x\n",
    "    global x\n",
    "\n",
    "    # Acquire the lock here\n",
    "    # This will prevent other threads from modifying x while we're using it\n",
    "    lock.acquire()\n",
    "\n",
    "    # Create a local variable to hold the value of x and increment it\n",
    "    local_x = x\n",
    "    local_x += thread_number\n",
    "\n",
    "    # Pause for a moment before updating the global x\n",
    "    time.sleep(0.1)\n",
    "    x =local_x\n",
    "\n",
    "    # We're done with x, so release the lock\n",
    "    lock.release()\n",
    "\n",
    "# Run each of the threads\n",
    "threads = []\n",
    "\n",
    "for i in range(5):\n",
    "    t = threading.Thread(target=increment_x_by_thread_number, args=(i,))\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "# What will the value of x be?\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, the function acquires the lock before accessing the global variable ```x```. This means that only one thread can access the global variable ```x``` at a time. Other threads will wait until we've done out calculations using ```x``` and updated its value before they can access it. This solves the problem we had before where the value of ```x``` was not the sum of the thread numbers.\n",
    "\n",
    "However, the example above means that each thread will be performing their calculations one after another, rather than concurrently. This means that we are not getting the full benefit of using threads. This means that we need to be careful when using locks, as they can slow down the execution of our code. We should only use locks when we need to, and try to keep the amount of code that is protected by a lock to a minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Global Interpreter Lock\n",
    "\n",
    "The Global Interpreter Lock (GIL) is a feature of the Python interpreter which means that only one thread can execute Python code at a time. This means that even if we have multiple threads, only one of them can be executing Python code at a time. This means that the GIL can limit the performance benefits of using threads in Python, particularly when the threads are executing a lot of native Python code. \n",
    "\n",
    "For example, the code below calculates the sum of all numbers between 1 and ```n``` using a single thread and then again using ```n_threads``` threads. The code reports the time each version takes to run. Note that, if you're using GitHub Codespaces to run this code, you may need to follow [these instructions](https://docs.github.com/en/codespaces/customizing-your-codespace/changing-the-machine-type-for-your-codespace) to increase the number of cores your Codespace uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "\n",
    "# SINGLE THREAD VERSION\n",
    "time.start = time.time()\n",
    "\n",
    "n = 10000000\n",
    "\n",
    "# Sum the numbers\n",
    "result = 0\n",
    "\n",
    "for i in range(n):\n",
    "    result += i\n",
    "\n",
    "print(f'Single-thread time taken: {time.time() - time.start}')\n",
    "\n",
    "# MULTI-THREAD VERSION\n",
    "# Runs on n_thread threads\n",
    "n_threads = 2\n",
    "time.start = time.time()\n",
    "\n",
    "results = [0] * n_threads\n",
    "\n",
    "def sum_numbers(start, end, thread_number):\n",
    "    for i in range(start, end):\n",
    "        results[thread_number] += i\n",
    "\n",
    "threads = []\n",
    "\n",
    "# Create n threads to sum the numbers\n",
    "n_per_thread = n // n_threads\n",
    "\n",
    "for i in range(n_threads):\n",
    "    t = threading.Thread(target=sum_numbers, args=(i * n_per_thread, (i + 1) * n_per_thread, i))\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "result = sum(results)\n",
    "\n",
    "print(f'Multi-thread time taken: {time.time() - time.start}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The times each version of the code takes to run will vary a little each time it's run, particularly for lower values of ```n```. However, we can still compare the runtime for different values of ```n``` and ```n_threads``` in the figure below:\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"resources/threading_sum.png\" alt=\"A figure showing the runtime for different numbers of threads as a function of n\" class=\"center\">\n",
    "</p>\n",
    "\n",
    "We can see that the time taken to run the code with multiple threads is not significantly faster than the time taken to run the code with a single thread and does not decrease as we use more threads. This is because the GIL is preventing the threads from truly running concurrently. This is an example of the GIL limiting the performance benefits of using threads in Python. For low values of ```n``` the single-threaded code is faster than the multi-threaded code. This is because the overhead of creating and managing threads is greater than the small benefits provided by using multiple threads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So Why Use Threads?\n",
    "\n",
    "Given the limitations of the GIL, you may be wondering why you would use ```threading``` at all. The reason is that there are certain tasks where the bottleneck is not the main bottleneck in the performance of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I/O Bound Tasks\n",
    "\n",
    "Some tasks are input/output (I/O) bound. This means that the task is waiting for some input or output to be completed before it can continue. For example, reading from a file, downloading data from the internet, or waiting for a user to input data are all I/O bound tasks. In these cases, the GIL is not a bottleneck as there is no Python code being interpreted. This means that we can use threads to run other tasks while we are waiting for the I/O bound task to complete.\n",
    "\n",
    "For example, the code below shows two different ways of writing a file and performing a calculation. In the first version, both calculations are done sequentially on the main thread. In the second version, writing the file is achieved in a separate thread while the main thread continues with the calculation. The code reports the time each version takes to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "import numpy as np\n",
    "\n",
    "n_data = 100000\n",
    "n_calculation = 4000000\n",
    "\n",
    "# Create some data to write\n",
    "data = np.random.rand(n_data)\n",
    "\n",
    "def some_calculation(n_calculation):\n",
    "    # Perform some calculation on the data\n",
    "    return sum([i ** 2 for i in range(n_calculation)])\n",
    "\n",
    "def write_data(data):\n",
    "    # Write the data to a file\n",
    "    np.savetxt('outputs/threading_io.txt', data, newline = ' ')\n",
    "\n",
    "# SINGLE THREAD VERSION\n",
    "time.start = time.time()\n",
    "\n",
    "write_data(data)\n",
    "\n",
    "print(f'Single-thread time taken to write: {time.time() - time.start}')\n",
    "\n",
    "time.start = time.time()\n",
    "\n",
    "calculation_result = some_calculation(n_calculation)\n",
    "\n",
    "print(f'Single-thread time taken for calculation: {time.time() - time.start}')\n",
    "\n",
    "# TWO THREAD VERSION\n",
    "time.start = time.time()\n",
    "\n",
    "# Create a thread to write the data\n",
    "t = threading.Thread(target=write_data, args=(data,))\n",
    "t.start()\n",
    "\n",
    "# Perform the calculation in the main thread\n",
    "calculation_result = some_calculation(n_calculation)\n",
    "\n",
    "# Wait for the write_data thread to finish\n",
    "t.join()\n",
    "\n",
    "print(f'Two-thread time taken for both operations: {time.time() - time.start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the code above repeatedly does not always behave in a consistent way. I ran the code above multiple times and found that the total time taken taken by the multi-threaded code could be anywhere between the time taken for the calculation alone by the single-threaded code and the time taken for the calculation and writing the file by the single-threaded code. This means, in this case, use a separate thread to write the output sometimes sped the code up, and rarely slowed down the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Python Code\n",
    "\n",
    "It's possible to write code in Python which runs non-Python code. When this happens, it's possible to release the GIL, allowing multiple copies of the code to run concurrently in different threads. This may in code you've written yourself or in a package you're using.\n",
    "\n",
    "For example, the ```numpy``` package is made up primarily of compiled C code and so functions in this package do not execute Python commands while it is running and release the GIL while running. This means that we can use threads to run multiple ```numpy``` operations concurrently. This can be useful when we have many expensive ```numpy``` operations to run and the bottleneck is the time taken to run these operations, rather than the time taken to run the Python code. For instance, the code below applies a series of 8 different functions to an array of ```n``` numbers. The single-threaded version of the code applies each sequentially, whilst the multi-threaded version of the code splits the operations across ```n_threads``` threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# The number of values we'll be taking the sin of\n",
    "n = 10000000\n",
    "\n",
    "# Generate n random numbers\n",
    "x = np.random.rand(n)\n",
    "\n",
    "functions = [np.sin, np.cos, np.tan, np.arcsin, np.arccos, np.arctan, np.exp, np.log]\n",
    "\n",
    "# SINGLE THREAD VERSION\n",
    "time.start = time.time()\n",
    "\n",
    "# Apply each function to the array\n",
    "for i in range(8):\n",
    "    functions[i](x)\n",
    "\n",
    "print(f'Single-thread time taken: {time.time() - time.start}')\n",
    "\n",
    "# MULTI-THREAD VERSION\n",
    "# Runs on n_thread threads\n",
    "n_threads = 2\n",
    "time.start = time.time()\n",
    "\n",
    "def add_vector_partial(start, end, x):\n",
    "    for i in range(start, end):\n",
    "        functions[i](x)\n",
    "\n",
    "threads = []\n",
    "\n",
    "# Create n threads to sum the numbers\n",
    "n_per_thread = 8 // n_threads\n",
    "\n",
    "for i in range(n_threads):\n",
    "    t = threading.Thread(target=add_vector_partial, args=(i * n_per_thread, (i + 1) * n_per_thread, x))\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(f'Multi-thread time taken: {time.time() - time.start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The runtimes are shown below:\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"resources/threading_numpy_functions.png\" alt=\"A figure showing the runtime for different numbers of threads as a function of n\" class=\"center\">\n",
    "</p>\n",
    "\n",
    "As before, for small values of ```n```, the multi-threaded code is slower then the single-threaded coded because of the overhead of setting up multiple threads. For larger values of ```n``` though, the extra threads make a difference, with the 8-thread version of the code running about three times quicker than the single-threaded version of the code. \n",
    "\n",
    "This is still not a perfect speedup. Part of this is because each each function we call may take a different time to run, and the 8-thread version will have to wait for the slowest function. This is an example of \"load-balancing\": the idea that parallel code will perform best when each parallel task takes the same amount of time to run. This is something the example above likely doesn't do perfectly.\n",
    "\n",
    "Another reason the example above doesn't achieve a perfect speedup is that much of Numpy is already parallelized. This means that even the single-threaded version of the code is already running multiple operations concurrently. This means that the speedup we get from using multiple threads is less than it would be if we were running code that was not already parallelized. This also means that trying to use threading to speed up a single Numpy operation is not normally effective as Numpy is already using multiple threads in a near optimal way. However, if there are several different Numpy operations which need to be run, then threading can allow them to be performed concurrently with at least some speedup.\n",
    "\n",
    "### An Escape from the GIL?\n",
    "\n",
    "[Python 3.13.0](https://docs.python.org/3/whatsnew/3.13.html) introduced [experimental support](https://docs.python.org/3/howto/free-threading-python.html) for a version of Python where the GIL is disabled. This \"free-threaded\" version of Python is intended to be bypass the limitations we've seen above. However, it it is currently around 40% slower than the standard version of Python for single-threaded tasks. When I experimented with this, I found it difficult to get working. This feature may become easier to use and more important in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "In the directory ```data``` there are then files named ```threading_0.txt``` to ```threading_9.txt``` which each contain a list of 1,000,000 numbers. The cell below contains some code which creates a [cumulative distribution function](https://en.wikipedia.org/wiki/Cumulative_distribution_function) for the collection of all the data in these files. The code reads in the data from each files, combines it into a single ```numpy``` array, then loops through a series of thresholds, counting the number of values in the array which are less than or equal to the threshold. The code then plots the cumulative distribution function.\n",
    "\n",
    "Your task is to produce a second version of the code which uses multiple threads to achieve this goal. You may use the first version of the code as a guide, particularly if you're less familiar with the Python constructs used in it. Consider how you may split the work between the threads, and check to see if doing so speeds up the code. A sample solution can be found in the file [sample_solutions/02-threading.ipynb](sample_solutions/02-threading.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# These are thresholds for the CDF\n",
    "# Use them in your code\n",
    "thresholds = np.linspace(4, 16, 121)\n",
    "\n",
    "\n",
    "# SINGLE-THREAD VERSION\n",
    "start_time = time.time()\n",
    "# Load the files into a number of numpy arrays within a list\n",
    "data_list = [np.loadtxt(f'data/threading_{i}.txt') for i in range(10)]\n",
    "\n",
    "# Concatenate the arrays in the list into a single array\n",
    "data = np.concatenate(data_list)\n",
    "\n",
    "# Create an array to hold the CDF\n",
    "cdf = np.zeros_like(thresholds)\n",
    "\n",
    "# Loop over the thresholds, counting the number of values below each threshold\n",
    "for i, threshold in enumerate(thresholds):\n",
    "    cdf[i] = np.sum(data < threshold)\n",
    "\n",
    "# Divide by the number of values to get the CDF\n",
    "cdf = cdf / len(data)\n",
    "\n",
    "print(f'Single-thread time taken: {time.time() - start_time}')\n",
    "\n",
    "# MULTI-THREAD VERSION\n",
    "start_time = time.time()\n",
    "# Write you code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f'Multi-thread time taken: {time.time() - start_time}')\n",
    "\n",
    "# Plot the CDF\n",
    "plt.plot(thresholds, cdf);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
