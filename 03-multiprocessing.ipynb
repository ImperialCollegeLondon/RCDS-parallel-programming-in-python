{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocessing\n",
    "\n",
    "The ```multiprocessing``` package has a similar interface to the ```threading``` module but, instead of spawning threads, it spawns processes. These are separate processes in the operating that have their own memory space. This means that sharing information between processes is more complicated than sharing information between threads. However, it also means that race conditions are less likely and, as each process is independent, the GIL is not a problem. This allows for code to be executed in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spawning Processes\n",
    "\n",
    "The main class is the ```Process``` class. We can create a new instance of this class using ```Process(target=func, args=(arg1, arg2))```. We can then start the process using ```p.start()``` and wait for it to finish using ```p.join()```. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__main__\n",
      "Main process is done\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def greeting(processes_number):\n",
    "    print(f'Hello from process number {processes_number}')\n",
    "\n",
    "processes = []\n",
    "\n",
    "print(__name__)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for i in range(2):\n",
    "        p =multiprocessing.Process(target=greeting, args=(i,))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    print('Main process is done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much of this is similar to what you've already done with threads, but there are a few important differences. \n",
    "\n",
    "The first is that you will notice that the result of the print statement in ```greetings``` is not displayed under the code cell. This is because it is being run in a separate process and so its output is not captured and displayed by the Jupyter notebook. A copy of this code is found in the file [```03_multiprocessing_scripts/print_example.py```](03_multiprocessing_scripts/print_example.py). You can run this code and see that the output of all processes is captured by the terminal and displayed there.\n",
    "\n",
    "The second thing to note is the line ```if __name == '__main__':```. This is necessary because, when a new process is spawned, it will run the code from the beginning of the script. This is necessary because the new process has a separate memory space and so needs to run the code again so that the function (in this case ```greetings```) is defined in the new process.\n",
    "\n",
    "To explain this, we need to consider the built in variable ```__name__```. This variable is created automatically when Python is run and will have different names in different circumstances. In the piece of code which is being run directly,it will have the value ```__main__```. In the case of a piece of code which is being run as the main script of a new process it will have the value ```__mp_main__```. You can check the values of ```__name__``` by running [```03_multiprocessing_scripts/print_example.py```](03_multiprocessing_scripts/print_example.py).\n",
    "\n",
    "This means that the line ```if __name__ == '__main__':``` will only be true in the main script and not in any new processes that are spawned. This is important because it means that the code inside this block will only be run in the main script and not in any new processes that are spawned. This prevents each new process from spawning more processes and so creating an infinite loop. We also include the code waiting for the processes to finish and the final call to the ```print``` function in the if-block so they are only run in the main script and not in any new processes that are spawned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Values from Processes\n",
    "\n",
    "Just like a thread created with the ```threading``` module, any value returned from a function called in a process will be lost. There are a few ways we can communicate between processes. We'll look at ```Pipe```, ```Queue```, ```Value``` and ```Array```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipes\n",
    "\n",
    "A pipe is a two-way communication channel between two processes. We can create a pipe using ```Pipe()```. The two ends of the pipe are known as connectors. These can be passed to two processes to allow communication between them. By default, communication is allowed in two directions. We can then use the ```send()``` and ```recv()``` methods of the connectors to send and receive data through the pipe. When the ```recv()``` method is called, the process will wait until data is available to be received.\n",
    "\n",
    "Note that there is a maximum size of data which can be sent through the pipe (this may be around 32MB depending on operating system).\n",
    "\n",
    "The example below shows a simple example using a pipe to communicate between the main process and a child process:\n",
    "\n",
    "```python\n",
    "import multiprocessing\n",
    "import numpy\n",
    "\n",
    "def calculate_sum(conn):\n",
    "    # Wait to receive an array from the parent process\n",
    "    array = conn.recv()\n",
    "    # Calculate the sum of the array\n",
    "    result = numpy.sum(array)\n",
    "    # Send the result back to the parent process\n",
    "    conn.send(result)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Create a Pipe() object\n",
    "    # This function returns a pair of connection objects connected by a pipe\n",
    "    parent_conn, child_conn = multiprocessing.Pipe()\n",
    "    # Create a process and pass the child connection object to it\n",
    "    # The process will implement the calculate_sum function\n",
    "    p = multiprocessing.Process(target=calculate_sum, args=(child_conn,))\n",
    "    # Start the process\n",
    "    p.start()\n",
    "    # Send an array to the child process\n",
    "    parent_conn.send(numpy.arange(1, 6))\n",
    "    # Receive the result from the child process\n",
    "    print(parent_conn.recv())\n",
    "    # Wait until the process is finished\n",
    "    p.join()\n",
    "    print('Main process is done')\n",
    "```\n",
    "\n",
    "The above code will not work in a Jupyter notebook due to incompatibilities between ```multiprocessing``` and Jupyter. However, you can run this code in a Python script and see that the result is printed to the terminal. A copy of this code is found in the file [```03_multiprocessing_scripts/pipe_example.py```](03_multiprocessing_scripts/pipe_example.py) which you can run.\n",
    "\n",
    "In the above code, the parent process creates a pipe and passes one end of the pipe to the child process. The parent process then sends an array to the child process. The child process receives the array, calculates the sum of the array and sends the result back to the parent process. The parent process then receives the result and prints it.\n",
    "\n",
    "This method of communicating requires careful thought regarding the order in which processes will need to communicate with each other to make sure data is sent and received in the correct order. This can be difficult to manage in more complex programs. If the processes are load-balanced, it can also lead to processes waiting for data from another process, reducing the benefits of parallel execution. Once we have more than one child process, we will need to create a pipe for each pair of processes that need to communicate, further increasing complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deadlocks\n",
    "\n",
    "A deadlock is a situation where two or more processes are waiting for each other before progressing. This can happen in a number of conditions in concurrent programming. One possible cause of deadlocks is when two processes are waiting for each other to send data through a pipe. The following code is an adapted version of the code above but without the call to ```parent_conn.send``` in the main thread:\n",
    "\n",
    "```python\n",
    "import multiprocessing\n",
    "import numpy\n",
    "\n",
    "def calculate_sum(conn):\n",
    "    # Wait to receive an array from the parent process\n",
    "    array = conn.recv()\n",
    "    # Calculate the sum of the array\n",
    "    result = numpy.sum(array)\n",
    "    # Send the result back to the parent process\n",
    "    conn.send(result)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Create a Pipe() object\n",
    "    # This function returns a pair of connection objects connected by a pipe\n",
    "    parent_conn, child_conn = multiprocessing.Pipe()\n",
    "    # Create a process and pass the child connection object to it\n",
    "    # The process will implement the calculate_sum function\n",
    "    p = multiprocessing.Process(target=calculate_sum, args=(child_conn,))\n",
    "    # Start the process\n",
    "    p.start()\n",
    "    # Receive the result from the child process\n",
    "    print(parent_conn.recv())\n",
    "    # Wait until the process is finished\n",
    "    p.join()\n",
    "    print('Main process is done')\n",
    "```\n",
    "\n",
    "This code can be run in the file [```03_multiprocessing_scripts/deadlock_example.py```](03_multiprocessing_scripts/deadlock_example_example.py). You will see that the code hangs and does not finish. This is because the parent process is waiting for the child process to send data through the pipe and the child process is waiting for the parent process to send data through the pipe. This is a deadlock. care should be taken to avoid situations like this in concurrent programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queues\n",
    "\n",
    "A queue is a datatype which allows for communication between many processes. We can create a queue using ```multiprocessing.Queue()```. We can then use the ```put()``` and ```get()``` methods to add and remove items from the queue. The data will be stored in a First In First Out (FIFO) order. The example below shows a simple example of how data is added to and removed from a queue using only the main process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "queue = multiprocessing.Queue()\n",
    "\n",
    "queue.put(1)\n",
    "queue.put(2)\n",
    "queue.put(3)\n",
    "\n",
    "print(queue.get())\n",
    "print(queue.get())\n",
    "print(queue.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A queue may be passed to multiple different processes and each processes with access to the ```Queue``` can add data to the queue or retrieve data from it. If many processes may add data to a ```Queue``` at the same time, the exact order in which they add data is not guaranteed as the order of execution across different processes is not guaranteed. This limits the way in which a ```Queue``` can be used as it may not be clear which process a piece of data is from. \n",
    "\n",
    "When the ```get``` method is called, the execution of the code will block (meaning \"wait\") until data is available in the queue. This means we don't need to worry about if the computations required to put data in the queue have been completed when we call the ```get``` method. However, we do need to make sure the same amount of data is added to the queue as is removed from it. If we try to remove more data from the queue than will be added to it, the code will block indefinitely.\n",
    "\n",
    "The queue is thread and process safe, meaning that it can be used to communicate between many processes without the need for locks. The example below shows how we can use a ```Queue``` to collect the results from an arbitrary number of processes:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "# Note the start time\n",
    "start_time = time.time()\n",
    "\n",
    "def find_smallest_multiple(n_data, factor, queue):\n",
    "    # This function generates n_data random integers and finds the smallest multiple of factor\n",
    "\n",
    "    # Initially we have found no multiples of factor\n",
    "    result = None\n",
    "\n",
    "    # Create the random data\n",
    "    data = np.random.randint(1, 1000, n_data)\n",
    "\n",
    "    for d in data:\n",
    "        # Loop over the data and check if it's a multiple of factor\n",
    "        if d % factor == 0:\n",
    "            # If it is, check if it's the smallest we've found so far\n",
    "            if result is None or d < result:\n",
    "                # Update the result\n",
    "                result = d\n",
    "\n",
    "    # After considering each value, put the result in the queue\n",
    "    queue.put(result)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Set up the problem data\n",
    "    n_processes = 2\n",
    "    n_data = int(1e6)\n",
    "    factor = 7\n",
    "    n_data_per_process = n_data // n_processes\n",
    "\n",
    "    # Set up the queue\n",
    "    queue = multiprocessing.Queue()\n",
    "\n",
    "    for i in range(n_processes):\n",
    "        # Spawn and start the processes\n",
    "        p = multiprocessing.Process(target=find_smallest_multiple, args=(n_data_per_process, factor, queue))\n",
    "        p.start()\n",
    "\n",
    "    # We haven't found any multiples of factor yet\n",
    "    result = None\n",
    "\n",
    "    for i in range(n_processes):\n",
    "        # Get each result from the queue\n",
    "        # The code will pause here while the main process waits for each child process to finish\n",
    "        r = queue.get()\n",
    "\n",
    "        if result is None or r < result:\n",
    "            # If it's smaller than the current result, update it\n",
    "            result = r\n",
    "\n",
    "    # Note the end time and print the elapsed time\n",
    "    end_time = time.time()\n",
    "    print(f'Time taken: {end_time - start_time}')\n",
    "\n",
    "    print(f'The smallest multiple of {factor} in the data is {result}')\n",
    "```\n",
    "\n",
    "This code can be run in the file [```03_multiprocessing_scripts/queue_example.py```](03_multiprocessing_scripts/queue_example.py). In the main process we create a ```Queue``` object and pass it to each of the child processes. Each child process calculates the smallest multiple of a given factor in a subset of the data and adds the result to the ```Queue```. \n",
    "\n",
    "The main process collects the same number of bits of data from the ```Queue``` as there are child processes. Initially, the processes won't have completed their calculations and added them to the ```Queue``` so the main process will block until the data is available. As the result from each thread is added to the ```Queue```, the main process will collect the data and process it. This sort of process is particularly well suited to a ```Queue``` as the order in which the data is added to the ```Queue``` is not important. We don't need to wait for the processes to finish as the ```queue.get()``` method will automatically block until data is available. As a result, we also don't need to create a list of the processes.\n",
    "\n",
    "We can observe the performance of the code by changing the number of processes and the size of the data:\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"resources/queue_smallest_factor.png\" alt=\"A figure showing the runtime for different numbers of processes as a function of n_data\" class=\"center\">\n",
    "</p>\n",
    "\n",
    "When we completely remove the multiprocessing and run the code in a single process, we can see that the runtime is much less for low values of ```n_data```. This is because spawning processes takes some time, slowing down the code. However, as the size of ```n_data``` increases, this overhead becomes less significant and at around 100,000,0000 data points, the performance of the multiprocessing code equals that of the serial implementation. For 10,000,000,000 pieces of data, the multiprocessing implementation with both 4 and 8 courses is around 4 times faster than the serial implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Values\n",
    "\n",
    "The ```multiprocessing``` module also provides a way to share data between processes using the ```Value``` class. This class create a variable which references the same location in our computer's memory for each process. This means that changes to the variable in one process will be reflected in all other processes.\n",
    "\n",
    "The data stored in ```Value```  will be in the form of a ```ctype``` object. This is a C-style data type which is used to store data in memory. The C family of languages underpins much of Python and other languages and this is why it is used here. When we create a ```Value``` object, we need to specify the type of data we want to store. We may import the different ```ctype``` objects from the ```ctypes``` module (which is part of the Python Standard Library). The most common types are:\n",
    "\n",
    "- ```ctype.c_int```: A 32-bit integer\n",
    "- ```ctype.c_double```: A double precision floating point number\n",
    "- ```ctype.c_bool```: A boolean value\n",
    "\n",
    "We can retrieve and set the value of a ```Value``` object using its ```value``` attribute. The example below shows how we can create a shared ```Value``` object and increment it in a child process:\n",
    "\n",
    "```python\n",
    "import multiprocessing\n",
    "import ctypes\n",
    "\n",
    "# Create a shared memory value\n",
    "# It is an integer with an initial value of 0\n",
    "v = multiprocessing.Value(ctypes.c_int, 0)\n",
    "\n",
    "def increment(v):\n",
    "    v.value += 1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Create a process that increments the value\n",
    "    p = multiprocessing.Process(target=increment, args=(v,))\n",
    "    p.start()\n",
    "    p.join()\n",
    "\n",
    "    # Print the value\n",
    "    print(v.value)\n",
    "\n",
    "```\n",
    "\n",
    "This code can be run in the file [```03_multiprocessing_scripts/value_example.py```](03_multiprocessing_scripts/value_example.py). \n",
    "\n",
    "As the data in a ```Value``` is shared between processes, it would now be possible to encounter race conditions as we did with threads. However, the ```Value``` class has a built in lock which we can access with the ```get_lock``` method and use to prevent this. We can use the ```acquire()``` and ```release()``` methods of the lock to acquire and release the lock, as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import ctypes\n",
    "\n",
    "# Create a shared memory value\n",
    "# It is an integer with an initial value of 0\n",
    "v = multiprocessing.Value(ctypes.c_int, 0)\n",
    "\n",
    "# Get the lock\n",
    "v.get_lock().acquire()\n",
    "# Do our calculations altering the value\n",
    "v.value += 1\n",
    "# Release the lock\n",
    "v.get_lock().release()\n",
    "\n",
    "print(v.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use a context manager to acquire and release the lock. The example below shows how we can use the lock:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import ctypes\n",
    "\n",
    "# Create a shared memory value\n",
    "# It is an integer with an initial value of 0\n",
    "v = multiprocessing.Value(ctypes.c_int, 0)\n",
    "\n",
    "with v.get_lock():\n",
    "    # Perform our calculations altering the value in the indented code\n",
    "    v.value += 1\n",
    "\n",
    "print(v.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a more Pythonic way of managing locks and is less error-prone, as we cannot forget to release the lock.\n",
    "\n",
    "The example below shows how we can use both types of locks to increment a ```Value``` object safely across multiple processes:\n",
    "\n",
    "```python\n",
    "import multiprocessing\n",
    "import ctypes\n",
    "\n",
    "def increment(v):\n",
    "    # Manually acquire and release the lock\n",
    "    v.get_lock().acquire()\n",
    "    v.value += 1\n",
    "    v.get_lock().release()\n",
    "\n",
    "    # Use the context manager to acquire and release the lock\n",
    "    with v.get_lock():\n",
    "        v.value += 100\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Create a shared memory value\n",
    "    # It is an integer with an initial value of 0\n",
    "    v = multiprocessing.Value(ctypes.c_int, 0)\n",
    "\n",
    "    # Create n_process processes which increment the value\n",
    "    n_process = 8\n",
    "    processes = []\n",
    "    for i in range(n_process):\n",
    "        p = multiprocessing.Process(target=increment, args=(v,))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "\n",
    "    for i in range(n_process):\n",
    "        p.join()\n",
    "\n",
    "    # Print the value\n",
    "    print(v.value)\n",
    "```\n",
    "\n",
    "This code can be run in the file [```03_multiprocessing_scripts/value_lock_example.py```](03_multiprocessing_scripts/value_lock_example.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrays\n",
    "\n",
    "The ```Array``` class of the ```multiprocessing``` module is similar to the ```Value``` class but allows us to store more than one value in a shared memory location. We can create an ```Array``` object using ```multiprocessing.Array()```. We need to specify the type of data we want to store and the size of the array. We can use the same ```ctype``` objects as we did with the ```Value``` class, and we set the initial values using a tuple of values, as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[0.0, 7.0, 0.0, 0.0, 0.0]\n",
      "0.0\n",
      "7.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import ctypes\n",
    "\n",
    "# Create a shared memory array\n",
    "# It is an array of 5 floats with an initial value of 0\n",
    "a = multiprocessing.Array(ctypes.c_double, (0, 0, 0, 0, 0))\n",
    "\n",
    "# We can access a single value from the array using an index\n",
    "print(a[1])\n",
    "\n",
    "# We can modify a single value in the array using an index\n",
    "a[1] = 7\n",
    "\n",
    "# We access every value in the array using ':' as an index\n",
    "print(a[:])\n",
    "\n",
    "# We can iterate over the array\n",
    "for x in a:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, we also saw how we can access and modify data in the array.\n",
    "\n",
    "An ```array``` has a lock in a similar way to a ```Value```.\n",
    "\n",
    "The code below shows how we can create an array which keeps track of the number of times each number has been rolled on a six-sided dice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
